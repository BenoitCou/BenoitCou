# BenoîtCou

I am a French double-degree student (CentraleSupélec & UCL) with a passion for machine learning and AI. Currently completing my MSc in Machine Learning at University College London and my Engineering degree at CentraleSupélec Paris, I bring hands-on experience in ML engineering, data science, and research. My background includes roles at Toyota Motor Europe, McKinsey & Company, and DeepMedical, where I delivered impactful AI solutions.

---
---

## Featured Projects

### [Tender-Synth](https://github.com/BenoitCou/Tender-Synth)
A Streamlit app to automate public tender processing:
- Upload PDFs, Word, Excel (CCTP, lot lists, drawings, price schedules).
- Detect relevant lots based on company skills.
- Summarize hundreds of pages into a Word report with images.
- Chat with documents via a RAG-based chatbot, including source citations and configurable keyword filters.

### [UCL COMP0197 — Applied Deep Learning Coursework 1]
Logistic regression and Extreme Learning Machines:
- Polynomial logistic models and custom losses with SGD.
- Gaussian-initialised ELMs, mixup augmentation, and ensemble regularization.
- Hyperparameter search and performance comparison.

### [UCL COMP0197 — Applied Deep Learning Coursework 1 - WeakSegNet]
Weakly-supervised segmentation framework built for the Oxford-IIIT Pet Dataset:
- Implemented a segmentation network.
- Conducted comparisons against fully supervised methods and key hyperparameter ablation.
- Explored pseudo-mask limitations and integration with foundation models.

### [COMP0078 — Supervised Learning Coursework 1]
Supervised learning experiments on toy data and the Boston Housing dataset:
- Polynomial regression with bias–variance analysis.
- Gaussian kernel ridge regression with cross-validation.
- k-NN implementation: error vs k and training-set size studies.
- Theoretical proofs on kernels and learning bounds.

### [COMP0078 — Supervised Learning Coursework 2]
Theoretical analyses in supervised learning:
- Rademacher complexity bounds and surrogate loss consistency.
- Kernel perceptron studies on handwritten digits with CV and error analysis.

### [COMP0086 — Probabilistic & Unsupervised Learning Coursework]
Hands-on probabilistic modeling and EM algorithms:
- Multivariate Bernoulli, model selection with marginal likelihoods.
- EM for mixtures of Bernoullis with convergence analysis.
- Kalman smoothing and Gibbs sampling for LDA.
- MCMC for decrypting text and optimisation exercises.

### [COMP0171 — Bayesian Deep Learning Coursework 1]
Bayesian inference and Laplace approximation:
- Custom MCMC for heteroskedastic Gaussian model (seven scientists).
- Bayesian logistic regression with MAP, Laplace, and model comparison.
- Feature engineering up to cubic terms achieving 92% test accuracy.

### [COMP0171 — Bayesian Deep Learning Coursework 2]
Advanced Bayesian neural networks and VAEs:
- SGLD sampling for uncertainty quantification and calibration on two-moons.
- Variational Autoencoder on MNIST: architecture, ELBO optimization, and latent-space visualization.
- Monte Carlo reconstruction and generation with under-10k parameters.

### [COMP0089 — Reinforcement Learning Coursework]
Multi-armed bandits, TD learning, actor-critic, and off-policy returns:
- UCB, ε-greedy, and softmax agents with regret analysis.
- Policy iteration, value iteration, and TD(0) for grid worlds.
- Actor-critic with JAX and advanced off-policy multi-step estimators.

---
